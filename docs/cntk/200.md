---
title: 200
summary: 200
authors:
    - Zhiyuan Chen
date: 2019-09-07 18:42:05
categories: 
    - CNTK
    - Introduction
tags:
    - CNTK
    - Introduction
    - Computer Vision
---

# 200

*本文翻译自微软官方文档[CNTK 200: A Guided Tour](https://cntk.ai/pythondocs/CNTK_200_GuidedTour.html)。*

本教程介绍了CNTK的许多高级功能，适用于之前曾接触过深度学习和/或其他深度学习工具集的人。如果你是初学者，我们建议你从[CNTK 101教程](https://cntk.ai/pythondocs/CNTK_101_LogisticRegression.html)开始，并在完成100系列的大部分教程后再来这里。

## 引言

欢迎来到CNTK！深度神经网络正在重新定义计算机程序的创建方式。除了命令式，功能性，声明式编程之外，我们现在还具有可区分的编程，可以从数据中有效地“学习”程序。

CNTK是Microsoft产品组用于为各种产品创建深层模型的主要工具，从语音识别和机器翻译到各种图像分类服务，再到必应搜索排名。

本教程是CNTK的导览。它主要面向新上手CNTK但具有深度神经网络经验的用户。重点将放在如何在CNTK中完成深度学习的基本步骤，我们将主要通过实例展示。此导览不是完整的API说明。相反，我们会将读者引用到文档和特定于任务的教程中，以获取更多详细信息。

要训​​练深层模型，你需要定义模型结构，准备数据，以便将数据输入CNTK，训练模型并评估其准确性，然后进行部署。

本教程的组织结构如下：

+ 定义 **模型结构**
    - CNTK编程模型：作为函数对象的网络
    - CNTK数据模型：张量和张量序列
    - 你的第一个CNTK网络：Logistic回归
    - 你的第二个CNTK网络：MNIST数字识别
    - 图谱API：再来一次MNIST数字识别
+ 提供 **数据**
    - 适合内存的小数据集：numpy/ scipy数组/
    - 大数据集：`MinibatchSource`类
    - 分步传输数据：你自己的小批次梯度循环
+ **训练**
    - 分布式训练
    - 记录
    - 检查点
    - 基于交叉验证的训练控制
    - 最终评估
+ **部署** 模型
    - 来自Python
    - 来自C++和C＃
    - 来自你自己的网络服务
    - 通过Azure Web服务
+ 总结

要运行本教程，你将需要CNTK v2，最好还有一个支持CUDA的GPU（没有GPU的深度学习可不好玩）。

我们从一些我们将在本教程的其余部分中使用的导入开始。

```python
from __future__ import print_function
import cntk
import numpy as np
import scipy.sparse
import cntk.tests.test_utils
cntk.tests.test_utils.set_device_from_pytest_env() # (only needed for our build system)
cntk.cntk_py.set_fixed_random_seed(1) # fix the random seed so that LR examples are repeatable
from IPython.display import Image
import matplotlib.pyplot
%matplotlib inline
matplotlib.pyplot.rcParams['figure.figsize'] = (40,40)
```

## 定义模型结构

让我们一起深入。下面我们将介绍CNTK的数据模型和CNTK的编程模型 - 作为函数对象的网络（即网络可以被称为函数，它还包含一些状态，权重或参数，在学习期间可以调整）。我们将使用CNTK的Functional API将其用于逻辑回归和MNIST数字识别。最后，CNTK还有一个较低级别的图形API。我们将用它复制一个例子。

### CNTK编程模型：作为函数对象的网络

在CNTK中，神经网络是一个函数对象。一方面，CNTK中的神经网络只是一个可以调用以将其应用于数据的函数。另一方面，神经网络包含可以像对象成员一样访问的可学习参数。复杂的网络可以由更简单的层次结构组成，比如说，代表层。函数对象方法类似于Keras，Chainer，Dynet，PyTorch和Sonnet。

下面展示了使用函数对象的伪代码，使用全连接层（在CNTK中称为Dense）作为例子：

```python
# *Conceptual* numpy implementation of CNTK's Dense layer (simplified, e.g. no back-prop)
def Dense(out_dim, activation):
    # create the learnable parameters
    b = np.zeros(out_dim)
    W = np.ndarray((0,out_dim)) # input dimension is unknown
    # define the function itself
    def dense(x):
        if len(W) == 0: # first call: reshape and initialize W
            W.resize((x.shape[-1], W.shape[-1]), refcheck=False)
            W[:] = np.random.randn(*W.shape) * 0.05
        return activation(x.dot(W) + b)
    # return as function object: can be called & holds parameters as members
    dense.W = W
    dense.b = b
    return dense

d = Dense(5, np.tanh)    # create the function object
y = d(np.array([1, 2]))  # apply it like a function
W = d.W                  # access member like an object
print('W =', d.W)
print('y =', y)
```

再次强调，这只是伪代码。事实上，CNTK函数对象不支持numpy数组。相反，它们在内部表示为C++中用于编码计算的图结构，类似于其他深度学习工具集。

```python
d = Dense(5, np.tanh)
```

实际上只是构建一个图，

```python
y = d(np.array([1, 2]))
```

是将数据喂给图结构引擎。

这个图结构包含在Python类中，该函数公开必要的接口，以便其他Python函数可以调用它并访问其成员（例如W和b）。

函数对象是CNTK的单一抽象，用于表示不同的操作，这些操作仅按约定区分：

+ 没有可学习参数的 **基本操作** （例如`+`，`*`，`sigmoid()`……）
+ **层** （`Dense()`，`Embedding()`，`Convolution()`……）。层将一个输入映射到一个输出，并且可以附加可学习的参数。
+ **循环步骤函数** （`LSTM()`，`GRU()`，`RNNStep()`）。步骤函数将先前状态和新输入映射到新状态。
+ **损失和度量函数** （`cross_entropy_with_softmax()`，`binary_cross_entropy()`，`squared_error()`，`classification_error()`……）。在CNTK中，损失和度量并不特别，它们只是函数。唯一的区别是，虽然CNTK的函数可以有一个或多个输出，但损失和度量必须具有单个输出。请注意，损失不必输出标量值：如果损失的输出不是标量，CNTK将自动将损失定义为输出的总和。可以通过自己显式执行缩减操作来覆盖此行为。
+ **模型** 。模型由用户定义。模型将特征映射到预测或分数，并最终部署。
+ **准则函数** 。准则函数将（特征，标签）映射到损失并且可选地映射到度量。训练器通过SGD优化损失，并记录指标。度量或许是不可微的，但损失一定是可微的。

高阶层将对象组合成更复杂的对象，包括：

+ 层堆叠（`Sequential()`，`For()`）
+ 循环（`Recurrence()`，`Fold()`，`UnfoldFrom()`，……）

网络通常通过使用现有CNTK函数（例如特定类型的神经网络层）并使用`Sequential()`组成它们来定义。此外，用户可以将自己的函数编写为任意Python表达式，只要这些表达式包含对CNTK数据类型的CNTK操作。Python表达式通过将它们包装在对`Function()`的调用中而转换为内部表示。表达式可以通过装饰器语法（`@Function`）编写为多行函数。

即使通过组合CNTK的原语无法表达操作，也有通过在Python（或C ++）中编写自己的“层”来扩展CNTK的机制。这是高级功能，你现在不必担心，但如果你需要它，最好了解它。

最后，CNTK函数对象可以轻松进行参数共享。如果在多个位置调用相同的函数对象，则所有调用自然会共享相同的可学习参数。要避免共享参数，只需创建两个不同的函数对象。

总之，函数对象是CNTK的单一抽象，用于方便地定义简单和复杂模型，参数共享和培训目标。

也可以根据其底层图形操作直接定义CNTK网络，类似于许多其他工具集。你可以在定义神经网络的两种风格之间自由混合和匹配。这将在下面进一步讨论。

### CNTK数据模型：张量和张量序列

CNTK可以对两种类型的数据进行操作：

+ 张量（即N维阵列），密集或稀疏
+ 张量序列

他们的区别在于张量的形状在操作期间是静态的，而张量序列的长度取决于数据。在CNTK中，我们使用轴来表示与numpy数组的尺寸相同的东西，即形状的张量（7,10,6）具有三个轴。张量具有静态轴，而序列具有附加的动态轴。因此，动态轴是可变长度轴。

分类数据表示为稀疏的独热张量（即除了在其编码的类别的位置处的单个1之外具有所有元素0）。这允许以统一的方式将嵌套和损失函数写为矩阵的积。

打印CNTK函数将为你提供类似于以下格式的输出：

```python
Operation(Sequence[Tensor[shape]], other arguments) -> Tensor[shape]
```

当 *Operation* 为`Composite`时，该函数代表其下方的整个图，且显示的内容仅为最后一个操作。该图具有一定数量的有特定类型期望的输入。打印函数时，你将注意到 **缺少批量维度**。CNTK对用户隐藏了批。我们希望用户在张量和序列中进行思考，并将小批次处理留给CNTK。与其他工具集不同，CNTK还可以自动将具有不同长度的序列批量分成一个小批次，并处理所有必要的填充和包装。像“bucketing”这样的解决方法是不需要的。我们将动态轴（批和序列）与静态轴分开的原因是因为影响这些轴的操作非常少。默认情况下，你希望对批处理中的每个示例以及序列的每个元素执行某些操作。只有少数特殊操作（例如循环或批标准化）需要处理这些轴。

### 你的第一个CNTK网络：Logistic回归

让我们将所有这些应用于一个非常简单的逻辑回归。对于这个例子，我们创建了一个二维正态分布数据点的合成数据集，它应该被归类为属于两个类中的一个。请注意，CNTK期望标签为独热编码。

```python
input_dim_lr = 2    # classify 2-dimensional data
num_classes_lr = 2  # into one of two classes

# This example uses synthetic data from normal distributions,
# which we generate in the following.
#  X_lr[corpus_size,input_dim] - input data
#  Y_lr[corpus_size]           - labels (0 or 1), one-hot-encoded
np.random.seed(0)
def generate_synthetic_data(N):
    Y = np.random.randint(size=N, low=0, high=num_classes_lr)  # labels
    X = (np.random.randn(N, input_dim_lr)+3) * (Y[:,None]+1)   # data
    # Our model expects float32 features, and cross-entropy
    # expects one-hot encoded labels.
    Y = scipy.sparse.csr_matrix((np.ones(N,np.float32), (range(N), Y)), shape=(N, num_classes_lr))
    X = X.astype(np.float32)
    return X, Y
X_train_lr, Y_train_lr = generate_synthetic_data(20000)
X_test_lr,  Y_test_lr  = generate_synthetic_data(1024)
print('data =\n', X_train_lr[:4])
print('labels =\n', Y_train_lr[:4].todense())
```

现在，我们定义模型函数。模型函数将输入数据映射到预测。它是培训过程的最终产品。在这个例子中，我们使用最简单的所有模型：逻辑回归。

```python
model_lr_factory = cntk.layers.Dense(num_classes_lr, activation=None)
x = cntk.input_variable(input_dim_lr)
y = cntk.input_variable(num_classes_lr, is_sparse=True)
model_lr = model_lr_factory(x)
```

接下来，我们定义准则函数。准则函数是训练器用于优化模型的准测：它将（输入矢量，标签）映射到（损失，度量）。损失被用于SGD更新。我们选择交叉熵。具体来说，`cross_entropy_with_softmax()`首先将`softmax()`函数应用于网络的输出，因为交叉熵需要概率。我们没有将`softmax()`包含在模型函数本身当中，因为它不需要使用模型。我们计算分类错误作为作为度量标准（此度量标准不可微）。

我们将准则函数定义为Python代码并将其转换为`Function`对象。单个表达式可以写为`Function(lambda x, y:expression of x and y)`，类似于Keras的`Lambda()`。为了避免对模型进行两次评估，我们使用带有装饰器语法的Python函数定义。这同时也是告诉CNTK输入数据的类型的时候。这些通过装饰器`@Function`完成：

```python
@cntk.Function
def criterion_lr_factory(data, label_one_hot):
    z = model_lr_factory(data)  # apply model. Computes a non-normalized log probability for every output class.
    loss = cntk.cross_entropy_with_softmax(z, label_one_hot) # applies softmax to z under the hood
    metric = cntk.classification_error(z, label_one_hot)
    return loss, metric
criterion_lr = criterion_lr_factory(x, y)
print('criterion_lr:', criterion_lr)
```

装饰器将Python函数“编译”为CNTK的内部图表示。因此，结果`criterion`不是Python函数，而是CNTK `Function`对象。

现在，我们已准备好训练我们的模型。

```python
learner = cntk.sgd(model_lr.parameters,
                   cntk.learning_parameter_schedule(0.1))
progress_writer = cntk.logging.ProgressPrinter(0)

criterion_lr.train((X_train_lr, Y_train_lr), parameter_learners=[learner],
                   callbacks=[progress_writer])

print(model_lr.W.value) # peek at updated W
```

`learner`是实际执行模型时更新的对象。其他学习器包括`momentum_sgd()`和`adam()`。`progress_writer`是一个内置的记录回调函数，用于打印输出，你也可以自己进行替换，或使用自带的`TensorBoardProgressWriter`来通过TensorBoard可视化训练进度。

`train()`函数将我们的数据`(X_train_lr，Y_train_lr)`一小批次一小批次的提供给模型并更新它，其中数据是一个元组，其顺序与`criterion_lr()`的参数相同。

让我们测试一下我们在测试集上的表现（这也会一小批次一小批次的运行）。

```python
test_metric_lr = criterion_lr.test((X_test_lr, Y_test_lr),
                                   callbacks=[progress_writer]).metric
```

最后，让我们通过我们的模型运行一些示例，看看它做的怎么样。啊，`criterion`知道输入类型，但是`model_lr`并不知道，所以我们得告诉它。

```python
model_lr = model_lr_factory(x)
print('model_lr:', model_lr)
```

现在，我们可以像调用任何Python函数一样调用它：

```python
z = model_lr(X_test_lr[:20])
print("Label    :", [label.todense().argmax() for label in Y_test_lr[:20]])
print("Predicted:", [z[i,:].argmax() for i in range(len(z))])
```

### 你的第二个CNTK网络：MNIST数字识别

让我们在实际任务 -- MNIST基准上做与上面一样的事情。这是深度学习的“hello, world”。MNIST是对扫描的手写数字进行识别。我们首先下载并准备数据。在教程103C中，你可以找到一种更简洁的方法来使用CNTK内置的便捷功能编写整个MNIST数字识别工作流程

```python
input_shape_mn = (28, 28)  # MNIST digits are 28 x 28
num_classes_mn = 10        # classify as one of 10 digits

# Fetch the MNIST data. Best done with scikit-learn.
try:
    from sklearn import datasets, utils
    mnist = datasets.fetch_mldata("MNIST original")
    X, Y = mnist.data / 255.0, mnist.target
    X_train_mn, X_test_mn = X[:60000].reshape((-1,28,28)), X[60000:].reshape((-1,28,28))
    Y_train_mn, Y_test_mn = Y[:60000].astype(int), Y[60000:].astype(int)
except: # workaround if scikit-learn is not present
    import requests, io, gzip
    X_train_mn, X_test_mn = (np.fromstring(gzip.GzipFile(fileobj=io.BytesIO(requests.get('http://yann.lecun.com/exdb/mnist/' + name + '-images-idx3-ubyte.gz').content)).read()[16:], dtype=np.uint8).reshape((-1,28,28)).astype(np.float32) / 255.0 for name in ('train', 't10k'))
    Y_train_mn, Y_test_mn = (np.fromstring(gzip.GzipFile(fileobj=io.BytesIO(requests.get('http://yann.lecun.com/exdb/mnist/' + name + '-labels-idx1-ubyte.gz').content)).read()[8:], dtype=np.uint8).astype(int) for name in ('train', 't10k'))

# Shuffle the training data.
np.random.seed(0) # always use the same reordering, for reproducability
idx = np.random.permutation(len(X_train_mn))
X_train_mn, Y_train_mn = X_train_mn[idx], Y_train_mn[idx]

# Further split off a cross-validation set
X_train_mn, X_cv_mn = X_train_mn[:54000], X_train_mn[54000:]
Y_train_mn, Y_cv_mn = Y_train_mn[:54000], Y_train_mn[54000:]

# Our model expects float32 features, and cross-entropy expects one-hot encoded labels.
Y_train_mn, Y_cv_mn, Y_test_mn = (scipy.sparse.csr_matrix((np.ones(len(Y),np.float32), (range(len(Y)), Y)), shape=(len(Y), 10)) for Y in (Y_train_mn, Y_cv_mn, Y_test_mn))
X_train_mn, X_cv_mn, X_test_mn = (X.astype(np.float32) for X in (X_train_mn, X_cv_mn, X_test_mn))

# Have a peek.
matplotlib.pyplot.rcParams['figure.figsize'] = (5, 0.5)
matplotlib.pyplot.axis('off')
_ = matplotlib.pyplot.imshow(np.concatenate(X_train_mn[0:10], axis=1), cmap="gray_r")
```

让我们定义CNTK模型函数来将（28x28）维图像映射到10维评分向量。我们将它包装在一个函数中，以便在本教程的后面我们可以轻松地重新创建它。对于那些熟悉Tutorial 103D的人，你将学习如何使用层库来组成更大的网络，以简单的方式训练和测试它们。

```python
def create_model_mn_factory():
    with cntk.layers.default_options(activation=cntk.ops.relu, pad=False):
        return cntk.layers.Sequential([
            cntk.layers.Convolution2D((5,5), num_filters=32, reduction_rank=0, pad=True), # reduction_rank=0 for B&W images
            cntk.layers.MaxPooling((3,3), strides=(2,2)),
            cntk.layers.Convolution2D((3,3), num_filters=48),
            cntk.layers.MaxPooling((3,3), strides=(2,2)),
            cntk.layers.Convolution2D((3,3), num_filters=64),
            cntk.layers.Dense(96),
            cntk.layers.Dropout(dropout_rate=0.5),
            cntk.layers.Dense(num_classes_mn, activation=None) # no activation in final layer (softmax is done in criterion)
        ])
model_mn = create_model_mn_factory()
```

这个模型有点复杂！它由几个卷积层和两个全连接层组成以用于分类，MNIST的典型目标。这演示了CNTK函数API的几个方面。

首先，我们使用CNTK的层库（`cntk.layers`）中的函数创建每个层。

其次，高阶层`Sequential()`创建一个新的函数，一个接一个地应用所有这些层。这是已知的[前向复合函数](https://zh.wikipedia.org/wiki/%E5%A4%8D%E5%90%88%E5%87%BD%E6%95%B0)。请注意，与其他工具集不同，你不能在随后`Add()`更多层到序列层。CNTK的`Function`对象是不可变的，除了可学习的参数（要编辑`Function`对象，你可以`clone()`它）。如果你更喜欢那种样式，请将层创建为Python列表并将其传递给`Sequential()`。

第三，上下文管理器`default_options()`允许为层的各种可选参数指定默认值，例如激活函数始终是`relu`，除非重写。

最后，请注意`relu`作为实际函数传递，而不是字符串。任何函数都可以是激活函数。它也可以直接传递Python lambda，例如`relu`也可以通过`activation=lambda x: cntk.ops.element_max(x, 0)`手动实现。

准则函数的定义与前面的示例类似，用于将图片（28x28）维特征和相应标签映射到损失和度量。

```python
@cntk.Function
def criterion_mn_factory(data, label_one_hot):
    z = model_mn(data)
    loss = cntk.cross_entropy_with_softmax(z, label_one_hot)
    metric = cntk.classification_error(z, label_one_hot)
    return loss, metric
x = cntk.input_variable(input_shape_mn)
y = cntk.input_variable(num_classes_mn, is_sparse=True)
criterion_mn = criterion_mn_factory(x,y)
```

对于训练，让我们把动量加入进来。

```python
N = len(X_train_mn)
lrs = cntk.learning_parameter_schedule_per_sample([0.001]*12 + [0.0005]*6 + [0.00025]*6 + [0.000125]*3 + [0.0000625]*3 + [0.00003125], epoch_size=N)
momentums = cntk.momentum_schedule_per_sample([0]*5 + [0.9990239141819757], epoch_size=N)
minibatch_sizes = cntk.minibatch_size_schedule([256]*6 + [512]*9 + [1024]*7 + [2048]*8 + [4096], epoch_size=N)

learner = cntk.learners.momentum_sgd(model_mn.parameters, lrs, momentums)
```

这看起来有点不寻常。首先，学习率被指定为列表（`[0.001] * 12 + [0.0005] * 6 +` ……）。与`epoch_size`参数一起，这告诉CNTK对于前12个周期使用0.001，接下来的六个周期使用0.0005，等等。

其次，学习率被指定为好像它应用于大小为1（每个样本）的小批次，并且动量作为时间常数。这些值直接指定每个样本的梯度对模型的贡献的权重，以及随着训练的进展其贡献如何衰减。CNTK将根据读者提供的数据的实际小批次大小来调整学习率和动量。缩放的净效果将使学习速度和动量好像应用于大小为1的小批次。这种独特的CNTK函数允许调整小批次大小而无需重新调整这些参数。在这里，我们将它从256增加到4096，导致最后的操作速度提高3倍（在Titan-X上）。

好的，现在让我们训练模型。在Titan-X上，这将运行大约一分钟。

```python
progress_writer = cntk.logging.ProgressPrinter()
criterion_mn.train((X_train_mn, Y_train_mn), minibatch_size=minibatch_sizes,
                   max_epochs=40, parameter_learners=[learner], callbacks=[progress_writer])
test_metric_mn = criterion_mn.test((X_test_mn, Y_test_mn), callbacks=[progress_writer]).metric
```

### 图谱API：再来一次MNIST数字识别

CNTK还允许使用图级API编写网络。这个API更冗长，但有时更灵活。以下定义了与上述相同的模型和准则函数，并将得到相同的结果。

```python
images = cntk.input_variable(input_shape_mn, name='images')
with cntk.layers.default_options(activation=cntk.ops.relu, pad=False):
    r = cntk.layers.Convolution2D((5,5), num_filters=32, reduction_rank=0, pad=True)(images)
    r = cntk.layers.MaxPooling((3,3), strides=(2,2))(r)
    r = cntk.layers.Convolution2D((3,3), num_filters=48)(r)
    r = cntk.layers.MaxPooling((3,3), strides=(2,2))(r)
    r = cntk.layers.Convolution2D((3,3), num_filters=64)(r)
    r = cntk.layers.Dense(96)(r)
    r = cntk.layers.Dropout(dropout_rate=0.5)(r)
    model_mn = cntk.layers.Dense(num_classes_mn, activation=None)(r)

label_one_hot = cntk.input_variable(num_classes_mn, is_sparse=True, name='labels')
loss = cntk.cross_entropy_with_softmax(model_mn, label_one_hot)
metric = cntk.classification_error(model_mn, label_one_hot)
criterion_mn = cntk.combine([loss, metric])
print('criterion_mn:', criterion_mn)
```
